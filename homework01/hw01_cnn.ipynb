{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "\n",
    "# 確定使用 CPU or Cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class DogDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, filenames, labels, transform):\n",
    "        self.filenames = filenames    # 資料集的所有檔名\n",
    "        self.labels = labels          # 影像的標籤\n",
    "        self.transform = transform    # 影像的轉換方式\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)    # return DataSet 長度\n",
    " \n",
    "    def __getitem__(self, idx):       # idx: Inedx of filenames\n",
    "        image = Image.open(self.filenames[idx]).convert('RGB')\n",
    "        image = self.transform(image) # Transform image\n",
    "        label = np.array(self.labels[idx])\n",
    "        return image, label           # return 模型訓練所需的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料處理\n",
    "train_transformer = transforms.Compose([\n",
    "transforms.Resize(256), # 將圖像大小調整到256x256像素\n",
    "transforms.CenterCrop(224), # 從圖像中心裁剪出224x224像素的區域\n",
    "transforms.ToTensor(), # 圖像轉換成PyTorch的Tensor\n",
    "# 標準化處理 mean 代表平均值 std 代表標準差 利用每個通道的像素減去相應的均值除以標準差 可使像素值分佈接近標準正態分佈\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數設定\n",
    "batch_size = 16                                  # Batch Size\n",
    "lr = 1e-5                                        # Learning Rate\n",
    "epochs = 30                                      # epoch 次數\n",
    "\n",
    "train_data_dir = 'train'                         # 訓練集資料夾名稱\n",
    "valid_data_dir = 'valid'                         # 驗證集資料夾名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試集設定\n",
    "def set_Train_Data(train_data_dir):\n",
    "    dataset = ImageFolder(train_data_dir)\n",
    "    # 建立所有類別的\n",
    "    character = [[] for i in range(len(dataset.classes))]\n",
    "\n",
    "    # 將每一類的檔名依序存入相對應的 list\n",
    "    for x, y in dataset.samples:\n",
    "        character[y].append(x)\n",
    "      \n",
    "    train_inputs, train_labels = [], []\n",
    "    \n",
    "    for i, data in enumerate(character): # 讀取每個類別中所有的檔名 (i: label, data: filename)\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(data)\n",
    "            \n",
    "        # 存訓練集\n",
    "        num_sample_train = int(len(data))\n",
    "        print(str(i) + ': ' + str(len(data)) + ' | ' + str(num_sample_train))\n",
    "        \n",
    "        for x in data[:num_sample_train]:\n",
    "            train_inputs.append(x)\n",
    "            train_labels.append(i)\n",
    "            \n",
    "\n",
    "    train_dataloader = DataLoader(DogDataset(train_inputs, train_labels, train_transformer),\n",
    "                                  batch_size = batch_size, shuffle = True)\n",
    "    return train_dataloader\n",
    "\n",
    "train_dataloader = set_Train_Data(train_data_dir)\n",
    "\n",
    "\n",
    "# 驗證集設定\n",
    "def set_Val_Data(valid_data_dir):\n",
    "    dataset = ImageFolder(valid_data_dir)\n",
    "    # 建立所有類別的\n",
    "    character = [[] for i in range(len(dataset.classes))]\n",
    "\n",
    "    # 將每一類的檔名依序存入相對應的 list\n",
    "    for x, y in dataset.samples:\n",
    "        character[y].append(x)\n",
    "      \n",
    "    val_inputs, val_labels = [], []\n",
    "    \n",
    "    for i, data in enumerate(character): # 讀取每個類別中所有的檔名 (i: label, data: filename)\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(data)\n",
    "\n",
    "        # 存驗證集\n",
    "        num_sample_val = int(len(data))\n",
    "        print(str(i) + ': ' + str(len(data)) + ' | ' + str(num_sample_val))\n",
    "        \n",
    "        for x in data[:num_sample_val] :\n",
    "            val_inputs.append(x)\n",
    "            val_labels.append(i)\n",
    "        \n",
    "\n",
    "    val_dataloader = DataLoader(DogDataset(val_inputs, val_labels, train_transformer),\n",
    "                                  batch_size = batch_size, shuffle = False)\n",
    "    return val_dataloader\n",
    "\n",
    "val_dataloader = set_Val_Data(valid_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = models.vgg16(pretrained=True).to(device)     # 使用內建的 model\n",
    "C.classifier[6] = nn.Linear(C.classifier[6].in_features, 15)  # 15個類別數\n",
    "\n",
    "optimizer_C = optim.Adam(C.parameters(), lr = lr) # 選擇你想用的 optimizer\n",
    "# summary(C, (3, 244, 244))                        # 利用 torchsummary 的 summary package 印出模型資訊，input size: (3 * 224 * 224)\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()                # 選擇想用的 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_epoch_C = []\n",
    "train_acc, val_acc, test_acc = [], [], []\n",
    "best_acc, best_auc = 0.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        correct_train, total_train = 0, 0\n",
    "        correct_val, total_val = 0, 0\n",
    "        train_loss_C = 0.0\n",
    "\n",
    "        C.train()  # 設定成訓練模式\n",
    "        print(f'Epoch: {epoch + 1} / {epochs}')\n",
    "        \n",
    "        # 訓練階段\n",
    "        for i, (x, label) in enumerate(train_dataloader):\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            optimizer_C.zero_grad()\n",
    "\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            C = C.to(device) # 將model設成 GPU\n",
    "\n",
    "            train_output = C(x)                         \n",
    "            train_loss = criterion(train_output, label)\n",
    "            # 更新梯度權重\n",
    "            train_loss.backward()             \n",
    "            optimizer_C.step()                       \n",
    "            \n",
    "            _, predicted = torch.max(train_output.data, 1)\n",
    "            total_train += label.size(0)\n",
    "            correct_train += (predicted == label).sum().item()\n",
    "            train_loss_C += train_loss.item()\n",
    "            \n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        print(f'Training - Epoch: {epoch + 1}, Loss: {train_loss_C / len(train_dataloader):.3f}, Accuracy: {train_accuracy:.3f}%')\n",
    "        \n",
    "        # 驗證階段\n",
    "        C.eval()  # 設定為評估模式\n",
    "        with torch.no_grad(): # 設定不要影響梯度\n",
    "            for i, (x, label) in enumerate(val_dataloader):\n",
    "                x, label = x.to(device), label.to(device)\n",
    "                val_output = C(x)\n",
    "                _, predicted = torch.max(val_output.data, 1)\n",
    "                total_val += label.size(0)\n",
    "                correct_val += (predicted == label).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        print(f'Validation - Accuracy: {val_accuracy:.3f}%')\n",
    "                                     \n",
    "        train_acc.append(train_accuracy)\n",
    "        val_acc.append(val_accuracy)\n",
    "        loss_epoch_C.append(train_loss_C / len(train_dataloader))\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f'Epoch time: {end_time - start_time:.3f} secs\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = './fig/'\n",
    "if not os.path.isdir(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "# 繪製訓練損失圖表\n",
    "plt.figure()\n",
    "plt.plot(list(range(epochs)), loss_epoch_C)  # 繪製訓練損失曲線\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('Loss'), plt.xlabel('Epoch')\n",
    "plt.legend(['Train Loss'], loc='upper left')\n",
    "plt.savefig(os.path.join(fig_dir, 'training_loss.png'))\n",
    "plt.show()\n",
    "\n",
    "# 繪製訓練和驗證準確率圖表\n",
    "plt.figure()\n",
    "plt.plot(list(range(epochs)), train_acc, label='Training Accuracy')  # 繪製訓練準確率曲線\n",
    "plt.plot(list(range(epochs)), val_acc, label='Validation Accuracy')  # 繪製驗證準確率曲線\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy (%)'), plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(fig_dir, 'accuracy.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 圖片預處理流程\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 遍歷圖片文件夾\n",
    "folder_path = 'testing'  # 你的圖片文件夾路徑\n",
    "output_file = 'test_data.csv'  # 輸出文件名\n",
    "\n",
    "Dogs = [\"Afghan\",\"Beagle\",\"Bloodhound\",\n",
    "        \"Bluetick\",\"Chihuahua\",\"Collie\",\n",
    "        \"Dingo\",\"French Bulldog\",\"German Sheperd\",\n",
    "        \"Malinois\",\"Newfoundland\",\"Pekinese\",\n",
    "        \"Pomeranian\",\"Pug\",\"Vizsla\"]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for img_name in os.listdir(folder_path):\n",
    "    img_path = os.path.join(folder_path, img_name)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = transform(img).unsqueeze(0)  # 增加一個批次維度\n",
    "    img = img.to(device)\n",
    "\n",
    "    with torch.no_grad():  # 不計算梯度\n",
    "        outputs = C(img)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    #print(f'{img_name}: {predicted.item()}')\n",
    "\n",
    "    if predicted.item() < 15:\n",
    "        predictions.append([img_name, Dogs[predicted.item()]])\n",
    "\n",
    "    else:\n",
    "        print(f'{img_name}: {predicted.item()}')\n",
    "        # 寫入預測結果，這裡假設predicted是類別索引\n",
    "        #print(f'Predicted class: {Dogs[predicted.item()]}')\n",
    "\n",
    "# 保存預測結果為xlsx\n",
    "df = pd.DataFrame(predictions, columns=['檔名', '結果'])\n",
    "output_file = 'test_data.xlsx'  # 輸出文件名\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print('預測結果已保存至', output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
