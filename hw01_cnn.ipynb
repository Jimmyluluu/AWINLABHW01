{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch import optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 確定使用 CPU or Cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實作一個可以讀取 stanford dog (mini) 的 Pytorch dataset\n",
    "class DogDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, filenames, labels, transform):\n",
    "        self.filenames = filenames    # 資料集的所有檔名\n",
    "        self.labels = labels          # 影像的標籤\n",
    "        self.transform = transform    # 影像的轉換方式\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)    # return DataSet 長度\n",
    " \n",
    "    def __getitem__(self, idx):       # idx: Inedx of filenames\n",
    "        image = Image.open(self.filenames[idx]).convert('RGB')\n",
    "        image = self.transform(image) # Transform image\n",
    "        label = np.array(self.labels[idx])\n",
    "        return image, label           # return 模型訓練所需的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256), # 將圖像大小調整到256x256像素\n",
    "    transforms.CenterCrop(224), # 從圖像中心裁剪出224x224像素的區域\n",
    "    transforms.ToTensor(), # 圖像轉換成PyTorch的Tensor\n",
    "    # 標準化處理 mean 代表平均值 std 代表標準差 利用每個通道的像素減去相應的均值除以標準差 可使像素值分佈接近標準正態分佈\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數設定\n",
    "batch_size = 32                                  # Batch Size\n",
    "lr = 1e-3                                        # Learning Rate\n",
    "epochs = 10                                      # epoch 次數\n",
    "\n",
    "train_data_dir = 'train'                         # 訓練集資料夾名稱\n",
    "valid_data_dir = 'valid'                         # 驗證集資料夾名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3888521505.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[37], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    for x in data[:num_sample_train]\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def set_Train_Data(train_data_dir):\n",
    "    dataset = ImageFolder(train_data_dir)\n",
    "    print(dataset)\n",
    "    # 建立所有類別的\n",
    "    character = [[] for i in range(len(dataset.classes))]\n",
    "    print(character)\n",
    "\n",
    "    # 將每一類的檔名依序存入相對應的 list\n",
    "    for x, y in dataset.samples:\n",
    "        character[y].append(x)\n",
    "        print(character[y])\n",
    "      \n",
    "    train_inputs, train_labels = [], []\n",
    "    \n",
    "    for i, data in enumerate(character): # 讀取每個類別中所有的檔名 (i: label, data: filename)\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(data)\n",
    "            \n",
    "        # 存訓練集\n",
    "        num_sample_train = int(len(data))\n",
    "        print(str(i) + ': ' + str(len(data)) + ' | ' + str(num_sample_train))\n",
    "        \n",
    "        for x in data[:num_sample_train]:\n",
    "            train_inputs.append(x)\n",
    "            train_labels.append(i)\n",
    "            \n",
    "\n",
    "    train_dataloader = DataLoader(DogDataset(train_inputs, train_labels, train_transformer),\n",
    "                                  batch_size = batch_size, shuffle = True)\n",
    "    return train_dataloader\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = set_Train_Data(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_Val_Data(valid_data_dir):\n",
    "    dataset = ImageFolder(valid_data_dir)\n",
    "    print(dataset)\n",
    "    # 建立所有類別的\n",
    "    character = [[] for i in range(len(dataset.classes))]\n",
    "    print(character)\n",
    "\n",
    "    # 將每一類的檔名依序存入相對應的 list\n",
    "    for x, y in dataset.samples:\n",
    "        character[y].append(x)\n",
    "        print(character[y])\n",
    "      \n",
    "    val_inputs, val_labels = [], []\n",
    "    \n",
    "    for i, data in enumerate(character): # 讀取每個類別中所有的檔名 (i: label, data: filename)\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(data)\n",
    "\n",
    "        # 存驗證集\n",
    "        num_sample_val = int(len(data))\n",
    "        print(str(i) + ': ' + str(len(data)) + ' | ' + str(num_sample_val))\n",
    "        \n",
    "        for x in data[:num_sample_val] :\n",
    "            val_inputs.append(x)\n",
    "            val_labels.append(i)\n",
    "        \n",
    "\n",
    "    val_dataloader = DataLoader(DogDataset(val_inputs, val_labels, train_transformer),\n",
    "                                  batch_size = batch_size, shuffle = False)\n",
    "    return val_dataloader\n",
    "\n",
    "val_transformer = set_Val_Data(valid_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = models.vgg16(pretrained=True).to(device)     # 使用內建的 model \n",
    "optimizer_C = optim.SGD(C.parameters(), lr = lr) # 選擇你想用的 optimizer\n",
    "summary(C, (3, 244, 244))                        # 利用 torchsummary 的 summary package 印出模型資訊，input size: (3 * 224 * 224)\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()                # 選擇想用的 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_epoch_C = []\n",
    "train_acc, val_acc, test_acc = [], [], []\n",
    "best_acc, best_auc = 0.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        correct_train, total_train = 0, 0\n",
    "        correct_val, total_val = 0, 0\n",
    "        train_loss_C = 0.0\n",
    "\n",
    "        C.train()  # 設定成訓練模式\n",
    "        print(f'Epoch: {epoch + 1} / {epochs}')\n",
    "        \n",
    "        # 訓練階段\n",
    "        for i, (x, label) in enumerate(train_dataloader):\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            optimizer_C.zero_grad()                     \n",
    "            train_output = C(x)                         \n",
    "            train_loss = criterion(train_output, label)\n",
    "            # 更新梯度權重\n",
    "            train_loss.backward()             \n",
    "            optimizer_C.step()                       \n",
    "            \n",
    "            _, predicted = torch.max(train_output.data, 1)\n",
    "            total_train += label.size(0)\n",
    "            correct_train += (predicted == label).sum().item()\n",
    "            train_loss_C += train_loss.item()\n",
    "            \n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        print(f'Training - Epoch: {epoch + 1}, Loss: {train_loss_C / len(train_dataloader):.3f}, Accuracy: {train_accuracy:.3f}%')\n",
    "        \n",
    "        # 驗證階段\n",
    "        C.eval()  # 設定為評估模式\n",
    "        with torch.no_grad(): # 設定不要影響梯度\n",
    "            for i, (x, label) in enumerate(val_dataloader):\n",
    "                x, label = x.to(device), label.to(device)\n",
    "                val_output = C(x)\n",
    "                _, predicted = torch.max(val_output.data, 1)\n",
    "                total_val += label.size(0)\n",
    "                correct_val += (predicted == label).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        print(f'Validation - Accuracy: {val_accuracy:.3f}%')\n",
    "                                     \n",
    "        train_acc.append(train_accuracy)\n",
    "        val_acc.append(val_accuracy)\n",
    "        loss_epoch_C.append(train_loss_C / len(train_dataloader))\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f'Epoch time: {end_time - start_time:.3f} secs\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"testing/0D69LppfiM6saZx8HnkE.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = './fig/'\n",
    "if not os.path.isdir(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "# 繪製訓練損失圖表\n",
    "plt.figure()\n",
    "plt.plot(list(range(epochs)), loss_epoch_C)  # 繪製訓練損失曲線\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('Loss'), plt.xlabel('Epoch')\n",
    "plt.legend(['Train Loss'], loc='upper left')\n",
    "plt.savefig(os.path.join(fig_dir, 'training_loss.png'))\n",
    "plt.show()\n",
    "\n",
    "# 繪製訓練和驗證準確率圖表\n",
    "plt.figure()\n",
    "plt.plot(list(range(epochs)), train_acc, label='Training Accuracy')  # 繪製訓練準確率曲線\n",
    "plt.plot(list(range(epochs)), val_acc, label='Validation Accuracy')  # 繪製驗證準確率曲線\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy (%)'), plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(fig_dir, 'accuracy.png'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
