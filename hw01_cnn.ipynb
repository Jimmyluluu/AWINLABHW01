{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch import optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 確定使用 CPU or Cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實作一個可以讀取 stanford dog (mini) 的 Pytorch dataset\n",
    "class DogDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, filenames, labels, transform):\n",
    "        self.filenames = filenames    # 資料集的所有檔名\n",
    "        self.labels = labels          # 影像的標籤\n",
    "        self.transform = transform    # 影像的轉換方式\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)    # return DataSet 長度\n",
    " \n",
    "    def __getitem__(self, idx):       # idx: Inedx of filenames\n",
    "        image = Image.open(self.filenames[idx]).convert('RGB')\n",
    "        image = self.transform(image) # Transform image\n",
    "        label = np.array(self.labels[idx])\n",
    "        return image, label           # return 模型訓練所需的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256), # 將圖像大小調整到256x256像素\n",
    "    transforms.CenterCrop(224), # 從圖像中心裁剪出224x224像素的區域\n",
    "    transforms.ToTensor(), # 圖像轉換成PyTorch的Tensor\n",
    "    # 標準化處理 mean 代表平均值 std 代表標準差 利用每個通道的像素減去相應的均值除以標準差 可使像素值分佈接近標準正態分佈\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數設定\n",
    "batch_size = 5                                  # Batch Size\n",
    "lr = 1e-3                                        # Learning Rate\n",
    "epochs = 2                                      # epoch 次數\n",
    "\n",
    "data_dir = 'train'                               # 資料夾名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_Train_Val_Data(data_dir):\n",
    "    dataset = ImageFolder(data_dir)\n",
    "    # 建立 20 類的 list\n",
    "    character = [[] for i in range(len(dataset.classes))]\n",
    "    \n",
    "    # 將每一類的檔名依序存入相對應的 list\n",
    "    for x, y in dataset.samples:\n",
    "        character[y].append(x)\n",
    "      \n",
    "    train_inputs, test_inputs = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "    \n",
    "    for i, data in enumerate(character): # 讀取每個類別中所有的檔名 (i: label, data: filename)\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(data)\n",
    "            \n",
    "        # -------------------------------------------\n",
    "        # 將每一類都以 8:2 的比例分成訓練資料和測試資料\n",
    "        # -------------------------------------------\n",
    "        num_sample_train = int(len(data) * 0.8)\n",
    "        num_sample_test = len(data) - num_sample_train\n",
    "        print(str(i) + ': ' + str(len(data)) + ' | ' + str(num_sample_train) + ' | ' + str(num_sample_test))\n",
    "        \n",
    "        for x in data[:num_sample_train] : # 前 80% 資料存進 training list\n",
    "            train_inputs.append(x)\n",
    "            train_labels.append(i)\n",
    "            \n",
    "        for x in data[num_sample_train:] : # 後 20% 資料存進 testing list\n",
    "            test_inputs.append(x)\n",
    "            test_labels.append(i)\n",
    "\n",
    "    train_dataloader = DataLoader(DogDataset(train_inputs, train_labels, train_transformer),\n",
    "                                  batch_size = batch_size, shuffle = True)\n",
    "    test_dataloader = DataLoader(DogDataset(test_inputs, test_labels, test_transformer),\n",
    "                                  batch_size = batch_size, shuffle = False)\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 105 | 84 | 21\n",
      "1: 123 | 98 | 25\n",
      "2: 147 | 117 | 30\n",
      "3: 107 | 85 | 22\n",
      "4: 108 | 86 | 22\n",
      "5: 114 | 91 | 23\n",
      "6: 129 | 103 | 26\n",
      "7: 93 | 74 | 19\n",
      "8: 109 | 87 | 22\n",
      "9: 108 | 86 | 22\n",
      "10: 78 | 62 | 16\n",
      "11: 103 | 82 | 21\n",
      "12: 149 | 119 | 30\n",
      "13: 148 | 118 | 30\n",
      "14: 81 | 64 | 17\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 244, 244]           1,792\n",
      "              ReLU-2         [-1, 64, 244, 244]               0\n",
      "            Conv2d-3         [-1, 64, 244, 244]          36,928\n",
      "              ReLU-4         [-1, 64, 244, 244]               0\n",
      "         MaxPool2d-5         [-1, 64, 122, 122]               0\n",
      "            Conv2d-6        [-1, 128, 122, 122]          73,856\n",
      "              ReLU-7        [-1, 128, 122, 122]               0\n",
      "            Conv2d-8        [-1, 128, 122, 122]         147,584\n",
      "              ReLU-9        [-1, 128, 122, 122]               0\n",
      "        MaxPool2d-10          [-1, 128, 61, 61]               0\n",
      "           Conv2d-11          [-1, 256, 61, 61]         295,168\n",
      "             ReLU-12          [-1, 256, 61, 61]               0\n",
      "           Conv2d-13          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-14          [-1, 256, 61, 61]               0\n",
      "           Conv2d-15          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-16          [-1, 256, 61, 61]               0\n",
      "        MaxPool2d-17          [-1, 256, 30, 30]               0\n",
      "           Conv2d-18          [-1, 512, 30, 30]       1,180,160\n",
      "             ReLU-19          [-1, 512, 30, 30]               0\n",
      "           Conv2d-20          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-21          [-1, 512, 30, 30]               0\n",
      "           Conv2d-22          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-23          [-1, 512, 30, 30]               0\n",
      "        MaxPool2d-24          [-1, 512, 15, 15]               0\n",
      "           Conv2d-25          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-26          [-1, 512, 15, 15]               0\n",
      "           Conv2d-27          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-28          [-1, 512, 15, 15]               0\n",
      "           Conv2d-29          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-30          [-1, 512, 15, 15]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 258.51\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 786.98\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, test_dataloader = split_Train_Val_Data(data_dir)\n",
    "C = models.vgg16(pretrained=True).to(device)     # 使用內建的 model \n",
    "optimizer_C = optim.SGD(C.parameters(), lr = lr) # 選擇你想用的 optimizer\n",
    "summary(C, (3, 244, 244))                        # 利用 torchsummary 的 summary package 印出模型資訊，input size: (3 * 224 * 224)\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()                # 選擇想用的 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_epoch_C = []\n",
    "train_acc, test_acc = [], []\n",
    "best_acc, best_auc = 0.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m x, label \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m optimizer_C\u001b[38;5;241m.\u001b[39mzero_grad()                         \u001b[38;5;66;03m# 清空梯度\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m train_output \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m                             \u001b[38;5;66;03m# 將訓練資料輸入至模型進行訓練 (Forward propagation)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m criterion(train_output, label)     \u001b[38;5;66;03m# 計算 loss\u001b[39;00m\n\u001b[1;32m     23\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()                           \u001b[38;5;66;03m# 將 loss 反向傳播\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torchvision/models/vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m     68\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/LabHomework01/myenv/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        iter = 0\n",
    "        correct_train, total_train = 0, 0\n",
    "        correct_test, total_test = 0, 0\n",
    "        train_loss_C = 0.0\n",
    "\n",
    "        C.train() # 設定 train 或 eval\n",
    "        print('epoch: ' + str(epoch + 1) + ' / ' + str(epochs))  \n",
    "        \n",
    "        # ---------------------------\n",
    "        # Training Stage\n",
    "        # ---------------------------\n",
    "        for i, (x, label) in enumerate(train_dataloader) :\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            optimizer_C.zero_grad()                         # 清空梯度\n",
    "            train_output = C(x)                             # 將訓練資料輸入至模型進行訓練 (Forward propagation)\n",
    "            train_loss = criterion(train_output, label)     # 計算 loss\n",
    "            train_loss.backward()                           # 將 loss 反向傳播\n",
    "            optimizer_C.step()                              # 更新權重\n",
    "            \n",
    "            # 計算訓練資料的準確度 (correct_train / total_train)\n",
    "            _, predicted = torch.max(train_output.data, 1)  # 取出預測的 maximum\n",
    "            total_train += label.size(0)\n",
    "            correct_train += (predicted == label).sum()\n",
    "            train_loss_C += train_loss.item()\n",
    "            iter += 1\n",
    "                    \n",
    "        print('Training epoch: %d / loss_C: %.3f | acc: %.3f' % \\\n",
    "              (epoch + 1, train_loss_C / iter, correct_train / total_train))\n",
    "        \n",
    "        # --------------------------\n",
    "        # Testing Stage\n",
    "        # --------------------------\n",
    "        C.eval() # 設定 train 或 eval\n",
    "        for i, (x, label) in enumerate(test_dataloader) :\n",
    "            with torch.no_grad():                           # 測試階段不需要求梯度\n",
    "                x, label = x.to(device), label.to(device)\n",
    "                test_output = C(x)                          # 將測試資料輸入至模型進行測試\n",
    "                test_loss = criterion(test_output, label)   # 計算 loss\n",
    "                \n",
    "                # 計算測試資料的準確度 (correct_test / total_test)\n",
    "                _, predicted = torch.max(test_output.data, 1)\n",
    "                total_test += label.size(0)\n",
    "                correct_test += (predicted == label).sum()\n",
    "        \n",
    "        print('Testing acc: %.3f' % (correct_test / total_test))\n",
    "                                     \n",
    "        train_acc.append(100 * (correct_train / total_train).cpu()) # training accuracy\n",
    "        test_acc.append(100 * (correct_test / total_test).cpu())    # testing accuracy\n",
    "        loss_epoch_C.append((train_loss_C / iter))            # loss \n",
    "\n",
    "        end_time = time.time()\n",
    "        print('Cost %.3f(secs)' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 1.2634e+00, -3.8915e+00, -4.1892e+00, -1.7547e+00, -2.3560e+00,\n",
      "         -2.9995e-01, -2.9813e+00,  7.3760e-02, -4.8823e-01, -1.6221e+00,\n",
      "         -3.0706e+00, -4.8587e+00, -2.4973e+00, -4.5340e+00, -4.6371e+00,\n",
      "         -3.1003e+00, -1.7444e+00, -3.2607e+00, -5.3675e+00, -1.4703e+00,\n",
      "         -4.2714e+00,  2.2688e+00, -1.1762e+00,  3.2696e-01,  2.1246e+00,\n",
      "         -2.6413e+00, -2.8121e+00, -4.7015e+00, -2.6089e+00, -2.0081e+00,\n",
      "         -5.5017e+00, -4.3101e+00, -3.1377e+00, -5.8334e-01, -1.5442e+00,\n",
      "         -2.9383e+00, -2.2122e+00, -3.5049e+00, -2.9092e+00, -4.5427e+00,\n",
      "         -5.5235e+00, -3.4826e+00, -6.6173e+00, -5.2529e-01, -5.2883e+00,\n",
      "         -3.1380e+00, -5.6731e+00, -4.4777e+00, -2.8200e+00, -3.9678e+00,\n",
      "         -3.7551e+00, -4.6246e-01, -2.2371e+00, -3.4817e+00, -2.2056e+00,\n",
      "         -3.4578e+00, -7.9014e+00, -4.1876e+00, -3.5674e+00, -1.6960e+00,\n",
      "         -2.5568e+00, -3.0883e+00,  4.1400e-01, -2.8174e+00, -2.3503e+00,\n",
      "         -2.0122e+00, -1.9189e+00, -2.5758e+00, -2.8601e+00, -3.7877e+00,\n",
      "         -2.1227e+00, -3.2555e+00, -3.1860e+00, -1.0274e-01, -2.7093e+00,\n",
      "         -2.8182e+00, -4.4369e+00, -3.1828e+00,  7.9668e-01, -2.7825e+00,\n",
      "         -2.0176e+00, -2.9505e+00, -1.5166e+00,  2.0077e-01, -3.7808e+00,\n",
      "         -3.0437e+00,  4.1840e-01, -1.7472e+00, -2.4021e+00, -3.2912e+00,\n",
      "         -4.6430e+00, -1.9881e+00, -2.6436e+00, -2.8249e+00, -2.8662e+00,\n",
      "         -7.6111e-01, -3.7452e+00, -3.2991e+00, -1.7237e+00,  5.0971e-01,\n",
      "         -2.8722e+00,  2.9797e+00, -3.0790e+00,  5.2443e-01, -1.4115e+00,\n",
      "         -3.4943e+00, -2.6829e+00,  5.1094e-01, -1.4415e+00, -2.3348e+00,\n",
      "          1.5573e+00,  6.4360e-01, -1.0383e+00, -3.5275e-01, -2.2321e+00,\n",
      "         -1.0609e+00, -7.3315e-01, -1.0671e+00, -2.8305e+00, -4.6961e+00,\n",
      "         -6.2421e+00, -2.9151e+00, -2.2743e+00, -2.8518e+00, -1.9178e+00,\n",
      "         -2.8096e+00,  1.7827e+00, -4.5779e-01, -1.2396e+00, -3.0485e+00,\n",
      "         -1.9216e+00, -1.1286e+00, -9.5015e-01,  2.7470e+00, -1.9820e-01,\n",
      "         -3.3330e+00, -5.2070e+00, -7.0518e+00, -1.9836e+00, -3.9565e+00,\n",
      "         -3.7740e+00, -3.8016e+00, -2.4073e+00, -4.3695e+00, -1.3778e+00,\n",
      "         -1.6486e+00, -2.2467e+00, -2.4433e-01, -3.6801e+00,  4.5640e-01,\n",
      "          1.2675e+00,  2.2029e+00,  6.1861e+00,  4.1976e+00,  7.6346e+00,\n",
      "          7.4422e+00,  5.8017e+00,  4.9648e+00,  4.1408e+00,  1.0571e+01,\n",
      "          2.1752e+01,  4.2614e+00,  2.3053e-01,  1.1332e+01,  3.8373e+00,\n",
      "          4.9914e+00,  2.9181e+00,  5.0917e+00,  7.9987e+00,  1.0645e+01,\n",
      "          1.1816e+01,  2.0031e+00,  7.1221e+00,  5.5843e+00,  3.0971e+00,\n",
      "          1.4504e+01,  1.3000e+01,  9.7217e+00,  6.3674e+00,  2.6176e+00,\n",
      "          2.6141e+00,  3.7393e+00,  5.5535e+00,  7.8794e+00,  9.5597e+00,\n",
      "          9.1240e+00,  7.1807e+00,  8.7040e+00,  7.9060e+00,  7.6468e+00,\n",
      "          1.0145e+01,  8.7205e+00,  8.5110e+00,  9.7440e+00,  8.7870e+00,\n",
      "         -2.2545e+00,  4.8824e+00,  6.2354e+00,  6.1384e+00,  6.3009e+00,\n",
      "          1.6419e+01,  7.8668e+00,  1.2033e+01,  2.8830e+00,  1.0496e+01,\n",
      "          5.7236e+00,  6.0222e+00,  1.2678e+01,  7.1578e+00,  5.5386e+00,\n",
      "          3.7672e+00,  7.9371e+00,  1.2838e+01,  1.0698e+01,  8.3621e+00,\n",
      "          4.7609e+00,  1.1397e+01,  5.3901e+00,  6.5984e+00,  1.2026e+01,\n",
      "          1.4698e+01,  6.0519e+00,  7.7606e+00, -2.9134e-01,  3.7975e+00,\n",
      "          6.7558e+00,  1.9118e+01,  3.8042e+00,  1.0235e+01,  8.9437e+00,\n",
      "          5.4450e+00,  9.1931e+00,  3.8064e+00,  7.1499e+00,  1.1252e+00,\n",
      "          7.3770e+00,  4.2659e+00, -7.3330e-01,  4.4207e+00,  5.3490e-01,\n",
      "          2.7839e+00,  2.4639e+00,  4.2990e+00,  9.6498e+00,  8.6102e+00,\n",
      "         -8.3265e-01,  1.0187e+01,  5.3732e+00,  1.3561e+00,  1.1519e+00,\n",
      "         -1.0823e+00,  1.8100e+00,  5.4008e+00,  2.7734e+00,  4.6431e-01,\n",
      "          1.1704e+01,  6.8859e+00,  7.6864e+00,  1.7925e+00,  3.4194e+00,\n",
      "          3.8692e+00,  2.5540e+00,  7.0777e+00,  2.2602e+00,  2.6754e+00,\n",
      "          3.4190e+00,  4.6614e+00,  7.4821e+00,  2.8330e+00,  5.3586e-01,\n",
      "          3.0939e+00,  3.1747e+00,  1.1715e+00,  4.6158e+00,  2.3375e+00,\n",
      "          1.6518e+00,  2.8207e+00, -9.0175e-01, -2.7021e+00, -2.8498e+00,\n",
      "         -1.3271e+00,  8.1513e-01,  2.2325e+00,  2.1318e+00, -1.4317e-01,\n",
      "         -9.4105e-01,  2.6629e+00,  4.6603e-01, -1.3901e+00, -2.7447e+00,\n",
      "         -1.3770e+00,  7.6842e+00,  6.5210e+00, -9.7276e-02,  4.3744e+00,\n",
      "         -2.8523e+00,  4.9021e+00, -2.1429e-01,  7.3117e-01,  3.7231e+00,\n",
      "         -2.4312e+00, -4.4005e+00, -3.8175e-01, -2.3350e+00, -3.7590e+00,\n",
      "         -4.0664e+00, -2.6761e+00, -3.7688e+00, -4.2311e+00, -3.1082e+00,\n",
      "         -1.4105e+00, -4.2319e+00, -4.4934e+00, -4.0571e+00, -3.0104e+00,\n",
      "         -4.9281e+00, -3.0632e+00, -3.0562e+00, -4.2771e+00, -5.5821e+00,\n",
      "         -6.4169e+00, -5.2918e+00, -2.1950e+00, -2.3428e+00, -4.7778e+00,\n",
      "         -3.5833e+00, -4.1691e+00, -4.4228e+00, -4.1069e+00, -3.5593e+00,\n",
      "         -1.1269e+00,  5.9664e-01,  1.3446e+00, -5.5140e+00, -2.2588e+00,\n",
      "          4.2043e-01, -1.9621e+00,  1.6308e-01, -4.1139e-01,  5.6188e+00,\n",
      "          1.5577e+00, -1.0998e+00, -1.1362e+00,  6.0581e-01, -1.2995e+00,\n",
      "          6.4997e+00,  1.4865e+00,  6.3520e-01,  1.9218e+00,  1.2691e+00,\n",
      "          1.6148e+00,  6.5725e+00,  2.8978e+00,  2.1054e+00,  4.4811e+00,\n",
      "          5.7503e+00, -5.6474e-01, -3.1175e+00, -1.8616e+00,  2.9805e-01,\n",
      "         -3.8680e-01, -2.1605e+00, -2.1992e+00, -3.3848e+00,  3.5879e+00,\n",
      "          2.6915e+00, -2.7276e+00, -2.8323e+00,  3.4765e+00, -1.4308e+00,\n",
      "         -1.8072e+00,  3.2484e+00,  1.3297e+00,  2.3108e+00,  1.4543e+00,\n",
      "          1.0485e+00, -2.7552e-01,  4.9915e-01, -6.7962e-02,  7.9308e-01,\n",
      "          7.9481e-01,  1.3598e+00, -2.4073e+00, -3.0541e+00, -1.3236e+00,\n",
      "          3.5341e+00,  3.6713e+00, -4.3799e+00, -3.8112e+00, -3.5137e-01,\n",
      "         -6.3819e-01, -4.5340e-01, -3.2131e+00, -4.6534e+00,  2.8695e-01,\n",
      "          6.7402e-01, -2.0387e+00, -3.6544e+00, -4.5911e+00,  2.8097e+00,\n",
      "          3.9695e+00, -1.4901e+00, -2.6119e+00, -7.2765e+00, -1.7737e+00,\n",
      "          1.0056e+00,  3.2554e-01, -6.2105e-01, -1.9440e-02,  6.0618e-01,\n",
      "         -1.9809e+00,  1.5232e+00,  2.6734e+00, -6.8550e-02, -2.2998e+00,\n",
      "         -6.8714e-01,  2.8951e+00,  1.3305e+00, -2.6218e+00, -2.4049e+00,\n",
      "         -1.0675e+00,  5.5176e-01, -3.5298e-01, -2.8721e+00, -2.4382e+00,\n",
      "         -1.9607e+00,  3.8886e-01,  3.7951e+00,  1.2880e+00, -6.0162e-01,\n",
      "          8.7943e-01,  2.8868e+00, -1.1636e+00, -4.1460e-01,  1.7500e+00,\n",
      "          7.0731e-01,  6.3789e-01, -6.6025e-01, -1.1905e+00, -1.2078e+00,\n",
      "         -1.2968e+00,  7.3992e-01, -1.8069e+00, -3.1680e+00,  1.7353e-01,\n",
      "          1.6233e+00, -1.7956e+00,  5.6334e-01, -1.3118e+00, -1.0997e+00,\n",
      "         -1.8307e+00,  1.6017e-01, -1.5450e+00, -5.7670e-01, -2.4265e+00,\n",
      "         -2.8126e+00,  3.2954e+00, -1.9707e-01, -1.7919e+00,  9.6033e-02,\n",
      "         -2.4704e+00,  3.5309e+00,  2.2385e+00,  2.8792e+00, -1.3692e+00,\n",
      "          2.4225e+00, -2.7305e+00, -1.4010e+00, -3.7066e-01,  4.8776e-01,\n",
      "         -3.0276e+00, -1.9378e+00,  1.5638e+00, -2.6367e-01,  1.0415e+00,\n",
      "         -1.1755e+00, -5.9700e-01, -1.8193e+00, -2.7065e+00,  1.5512e-01,\n",
      "          9.8473e-01, -3.0972e+00, -1.3095e+00, -3.0981e+00, -2.5643e+00,\n",
      "         -2.9681e+00, -1.5642e+00, -1.0492e+00, -2.8969e+00, -1.6687e+00,\n",
      "         -1.5117e+00,  2.6900e+00, -2.2817e+00, -3.9858e-01,  2.4348e+00,\n",
      "         -1.6412e+00, -2.1337e+00, -1.8438e+00, -1.2296e+00,  1.0060e+00,\n",
      "         -5.3210e+00,  5.8622e+00,  3.0079e+00, -9.7277e-01, -1.6902e+00,\n",
      "          1.9862e-01, -5.7088e-03, -4.7126e-01, -3.1304e+00, -2.5266e+00,\n",
      "         -2.4728e+00,  3.5931e-01, -1.3516e+00, -1.9157e+00,  2.6867e+00,\n",
      "          1.8691e+00,  1.8448e-01, -1.1768e+00, -1.1144e+00,  2.0081e+00,\n",
      "         -3.7619e-01,  1.1283e+00,  2.1255e+00,  1.7262e+00,  5.1520e-01,\n",
      "         -2.9794e-01, -2.7995e+00, -3.4802e+00, -2.7087e+00, -2.2515e+00,\n",
      "         -2.7246e+00,  3.5331e-01, -3.1039e-01, -3.2677e+00,  2.9991e+00,\n",
      "         -4.0659e+00, -3.2761e+00,  1.0139e+00, -5.2072e-01,  2.3785e+00,\n",
      "         -3.6794e+00,  1.1617e+00, -4.3350e-01,  1.3111e+00, -1.9797e+00,\n",
      "         -2.7661e-02, -2.3902e+00, -3.8197e+00,  1.2905e+00, -2.1198e+00,\n",
      "         -1.4889e+00, -3.9843e+00,  9.6839e-01, -4.3499e-01, -1.6242e+00,\n",
      "         -1.5757e+00,  1.7836e-01, -6.8011e-01, -1.7151e+00,  1.8742e+00,\n",
      "         -2.6975e+00,  9.5434e-01,  3.1186e+00, -6.3193e+00,  1.0027e-01,\n",
      "         -4.3612e+00, -4.4929e-01, -2.5109e+00,  4.3701e+00, -4.3586e-01,\n",
      "         -6.4962e-01, -2.0335e+00, -1.9967e+00, -2.1900e+00, -1.3493e-01,\n",
      "          1.4023e+00, -4.7837e+00,  6.5823e-01,  5.3339e+00, -1.6845e+00,\n",
      "          2.8730e-01, -2.0907e+00, -8.2589e-01,  5.5543e-01,  2.9842e+00,\n",
      "          2.6434e+00,  1.8719e+00, -1.0325e+00,  7.5001e-01,  2.3066e+00,\n",
      "          3.6233e-01, -1.8208e+00, -4.0192e+00, -1.0264e+00,  1.5432e+00,\n",
      "          1.4581e+00,  3.6773e-01, -2.3007e+00, -6.5637e-01, -2.8577e+00,\n",
      "         -4.2709e-01,  4.9118e+00,  1.3848e+00,  3.4956e-01, -4.2001e+00,\n",
      "         -3.6714e+00, -2.4650e+00,  2.9574e-01, -1.3651e+00,  6.3023e-01,\n",
      "          4.7454e+00, -1.4727e+00, -7.5159e-01, -2.1700e+00,  2.1561e+00,\n",
      "         -9.2159e-01, -3.1869e-01,  7.6916e-01, -1.6988e+00, -4.6308e-01,\n",
      "         -9.6403e-01,  3.5018e+00, -3.6871e+00, -1.5438e+00,  6.9387e-01,\n",
      "         -3.6593e+00, -2.4276e+00,  1.4284e+00, -3.3162e+00, -2.9761e+00,\n",
      "          1.5217e-01, -8.8451e-01, -2.4097e+00, -2.6729e+00, -2.9773e+00,\n",
      "         -1.4788e+00,  1.9467e+00, -2.1236e+00,  4.0811e+00,  3.2449e+00,\n",
      "         -4.9102e+00,  3.1783e-01,  2.9123e-01,  1.7694e+00, -2.4868e+00,\n",
      "          1.6020e+00,  2.0047e+00, -1.6192e+00, -4.8498e-01,  5.5371e-01,\n",
      "         -2.1975e+00, -9.7882e-01,  9.1459e-01,  2.0509e+00,  1.7730e+00,\n",
      "          3.8825e+00, -8.9145e-01, -3.1083e+00, -3.0777e+00, -1.5624e+00,\n",
      "          2.4649e+00, -2.9089e-01, -2.3126e+00,  1.2844e+00, -1.0706e+00,\n",
      "         -8.6739e-01, -1.0797e+00,  3.6029e+00, -1.2445e+00, -1.7193e+00,\n",
      "         -2.8509e+00,  5.3622e-01,  1.3568e+00, -3.3292e+00, -4.5110e+00,\n",
      "          1.8841e-01,  8.1326e+00, -2.4636e+00,  3.7695e+00, -3.8688e+00,\n",
      "          6.0652e-01, -1.0555e+00, -9.4649e-01, -3.6816e-01, -1.0075e+00,\n",
      "         -5.7137e+00, -1.5916e+00,  8.8678e-01, -3.0863e+00,  6.3864e+00,\n",
      "          2.4578e+00,  9.1987e-01, -2.1217e+00,  1.9281e+00, -1.2695e+00,\n",
      "         -2.7936e+00, -1.5777e+00,  3.0176e+00,  1.2468e+00,  2.6972e+00,\n",
      "         -7.2978e-01,  2.2637e+00,  4.4201e-01,  6.4821e-01, -3.8986e+00,\n",
      "          1.8511e+00, -1.4000e+00, -5.3746e-01,  4.1166e+00, -6.2025e+00,\n",
      "         -3.3128e+00, -2.1294e+00, -3.6433e+00, -5.7212e-01, -3.6304e+00,\n",
      "          8.6238e-01,  1.4038e+00,  1.5496e+00,  1.0600e-01, -2.6966e+00,\n",
      "         -7.7389e-01, -2.9459e+00, -2.0844e+00, -3.3341e+00, -1.6394e-01,\n",
      "          9.8663e-02, -1.8215e+00,  1.0672e+00,  3.6399e+00, -3.5448e-01,\n",
      "         -3.1840e-01,  2.1004e+00, -1.8708e+00,  2.1396e+00, -2.4935e-01,\n",
      "          3.0266e+00, -1.1616e+00, -5.5341e-01, -1.1144e+00,  9.1422e-01,\n",
      "          1.2053e+00,  5.0221e-01, -2.3300e+00,  1.0386e+00, -8.5739e-01,\n",
      "         -3.3148e-01, -4.9430e+00, -4.8364e-01, -3.0519e+00, -3.4608e+00,\n",
      "          1.2079e+00,  1.7236e+00,  5.9030e-01,  6.8827e-02, -3.2029e+00,\n",
      "         -3.6855e-01,  3.3404e+00,  1.9613e+00,  1.1736e+00, -1.8515e+00,\n",
      "          4.7126e-01, -2.1669e+00, -1.0558e+00, -6.7797e-01, -6.7059e-01,\n",
      "          5.0438e-01, -5.2358e-01, -5.3398e+00, -1.9623e-01, -2.5627e+00,\n",
      "         -4.4006e+00, -2.2343e-03,  7.4947e-01, -1.2384e+00, -3.2960e+00,\n",
      "          3.7671e+00, -2.2234e+00, -1.7452e+00, -2.3268e+00,  1.7890e+00,\n",
      "         -1.1441e+00,  8.0303e-01, -1.2812e-01, -4.7684e+00, -1.9122e+00,\n",
      "          6.3802e-01, -2.6917e+00,  7.8879e-01, -3.4256e+00, -9.8499e-01,\n",
      "         -7.1513e-03, -1.3716e+00,  9.5847e-01,  3.4845e+00,  1.2565e-01,\n",
      "         -1.2810e+00, -1.2532e+00,  3.6810e-01, -1.7780e+00,  2.8059e-01,\n",
      "         -1.6559e+00,  1.3940e+00, -1.9388e+00, -2.8363e+00, -9.1319e-01,\n",
      "          3.7421e+00, -3.1369e+00,  1.0729e+00,  3.7962e-01, -3.2950e+00,\n",
      "         -2.0593e+00,  2.7160e+00, -2.1083e+00,  8.6822e-01, -1.0468e+00,\n",
      "         -4.3892e+00, -2.6680e+00,  2.2122e+00,  1.8893e+00,  3.9439e-01,\n",
      "         -2.3826e+00,  8.3533e-01,  6.6231e-01, -1.3170e+00,  2.5006e+00,\n",
      "         -1.4022e+00, -1.4457e+00, -1.9078e+00, -2.1021e+00,  1.3677e+00,\n",
      "         -1.2093e+00,  1.6280e+00, -3.1560e+00, -2.4087e+00,  4.2698e+00,\n",
      "         -3.4344e-01,  9.6811e-01,  2.0207e+00,  1.6167e-01, -7.8129e-01,\n",
      "          1.2814e+00,  3.6046e+00,  1.6575e+00,  8.0976e-01, -3.2471e+00,\n",
      "         -5.1381e+00,  4.2834e-01, -1.0190e+00, -2.1386e+00, -2.5097e+00,\n",
      "         -3.5085e+00,  1.2806e-01,  4.6638e+00,  2.4782e-01,  6.9393e-01,\n",
      "         -2.0926e+00,  7.7817e-01, -6.5298e-02, -4.4095e+00, -1.3960e+00,\n",
      "         -5.1329e-01,  3.9885e-02, -8.4016e-01,  9.9989e-02,  5.3101e-01,\n",
      "         -8.5349e-01,  2.6682e+00, -3.2499e-01, -1.4232e+00,  6.2257e+00,\n",
      "          9.2934e-01, -2.8569e+00,  1.3932e+00,  9.8156e-01,  7.3971e-01,\n",
      "         -1.8324e+00,  2.0064e+00,  4.3053e-01, -3.5934e+00, -1.5766e+00,\n",
      "          2.4375e+00, -9.1923e-01,  9.7366e-01, -3.8178e-01, -7.8089e-01,\n",
      "          5.5136e+00, -3.1468e+00,  1.2352e+00, -1.9064e+00, -2.2383e+00,\n",
      "          1.2585e+00, -3.1048e+00,  4.4361e-01, -4.2466e+00,  1.7482e+00,\n",
      "         -1.8095e+00, -2.6190e+00, -5.1702e-01,  7.7174e-01,  2.6214e+00,\n",
      "         -7.0054e-01, -8.6240e-02, -2.6025e-01,  6.0508e+00,  5.4774e-01,\n",
      "         -2.1536e+00,  7.7108e-01, -2.2758e+00, -4.3522e+00, -3.9642e+00,\n",
      "         -4.1806e-01,  4.3656e+00,  3.9997e+00, -4.4069e+00, -2.1973e+00,\n",
      "          2.5259e+00,  2.1187e+00,  8.6880e-02, -1.5593e+00, -4.6059e-01,\n",
      "         -5.1887e+00,  1.7908e+00, -4.8611e+00, -1.6408e+00, -1.0284e+00,\n",
      "         -2.7525e+00, -2.2794e+00, -4.5526e+00, -6.0382e+00,  1.2738e+00,\n",
      "          6.3401e-01, -3.9730e-01, -4.7728e-01, -4.6483e+00, -2.6653e+00,\n",
      "         -3.8010e+00,  9.6586e-02, -9.7952e-02, -1.8477e+00,  1.2759e+00,\n",
      "          2.1110e+00, -3.0498e-01, -3.4628e-01, -7.9485e-01,  1.0547e-01,\n",
      "         -2.6751e+00, -8.7017e-01, -3.2952e-01,  1.0303e+00, -4.4720e+00,\n",
      "         -4.0316e+00, -2.3626e+00, -3.0072e+00, -4.3326e+00, -1.9709e+00,\n",
      "         -2.7911e-01, -1.9879e-02, -5.1641e+00,  6.8256e-01, -4.6679e-01,\n",
      "         -3.1019e+00, -1.3724e+00, -2.8982e+00, -2.9789e+00, -9.8944e-02,\n",
      "         -1.7372e+00, -2.8432e+00, -3.4317e+00, -2.7897e+00,  4.7027e-01,\n",
      "         -4.6211e-01,  3.8592e-01, -2.4940e-01, -6.0969e-01,  4.3495e-01,\n",
      "          2.0763e+00, -6.0168e-01,  3.7187e+00,  3.1688e-01, -1.3012e-01,\n",
      "         -3.0777e-01,  1.1771e+00,  2.0231e+00, -3.1696e+00,  1.5432e+00,\n",
      "         -5.0649e+00, -2.4456e+00, -1.1596e+00, -2.5263e+00, -5.4508e+00,\n",
      "         -4.2532e+00,  7.7591e-02, -1.9961e+00,  8.9825e-01, -1.9271e+00,\n",
      "          1.1493e+00,  1.8609e+00, -4.2705e-01, -4.9976e-01, -2.4293e+00]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# Preprocess the input image\n",
    "\n",
    "\n",
    "img = Image.open(\"train/Afghan/001.jpg\")\n",
    "img_t = train_transformer(img)\n",
    "batch_t = img_t.unsqueeze(0)\n",
    "\n",
    "# Use the model to make predictions\n",
    "vgg16.eval()\n",
    "out = vgg16(batch_t)\n",
    "print()\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
